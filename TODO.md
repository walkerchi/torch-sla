## Functionality

- [x] sparse linear solve
- [ ] sparse eigen vals
- [x] sparse determination
- [ ] non linear solve 
- [ ] ODE operator
- [ ] matrix partition

## Documentation Completeness Check

### Sparse Determination (det) Implementation

| Feature | README | Examples | Docs | Benchmarks | Tests | Status |
|---------|--------|----------|------|------------|-------|--------|
| **Basic Usage** | ✅ | ✅ | ✅ | ✅ | ✅ | Complete |
| **Gradient Support** | ✅ | ✅ | ✅ | ✅ | ✅ | Complete |
| **CPU Backend** | ✅ | ✅ | ✅ | ✅ | ✅ | Complete |
| **CUDA Backend** | ✅ | ✅ | ✅ | ✅ | ✅ | Complete |
| **Batched Matrices** | ✅ | ✅ | ✅ | N/A | ✅ | Complete |
| **Distributed (DSparseTensor)** | ✅ | ✅ | ✅ | N/A | ✅ | Complete |
| **Mathematical Formulas** | ✅ | N/A | ✅ | N/A | N/A | Complete |
| **Performance Benchmarks** | ✅ | N/A | ✅ | ✅ | N/A | Complete |
| **Error Handling** | ✅ | ✅ | ✅ | N/A | N/A | Complete |
| **Numerical Stability Notes** | ✅ | ✅ | ✅ | ✅ | N/A | Complete |

**Summary:**
- ✅ Core functionality: 100% complete (10/10 features)
- ✅ Documentation: 100% complete (README, Examples, Docs)
- ✅ Examples: 8 comprehensive examples covering all use cases
- ✅ Tests: All functionality tested and verified
- ✅ Benchmarks: Performance benchmark script with visualization
- ✅ Error handling: Proper error messages and warnings
- ✅ Numerical stability: Documented overflow/underflow issues

**Files Created/Updated:**
- `README.md`: Added det() to Matrix Operations, Gradient Support, and Performance Tips
- `examples/determinant.py`: 8 examples (basic, gradient, CUDA, batched, distributed, optimization, stability, properties)
- `docs/source/examples.rst`: Dedicated "Determinant with Gradient Support" section with math formulas
- `benchmarks/benchmark_determinant.py`: Performance benchmark with CPU/CUDA comparison
- `torch_sla/sparse_tensor.py`: DetAdjoint class and det() method
- `torch_sla/backends/scipy_backend.py`: scipy_det() function using LU decomposition
- `torch_sla/distributed.py`: det() for DSparseTensor (with gather) and DSparseMatrix (error handling)

**Implementation Details:**
- **Gradient formula**: ∂det(A)/∂A_ij = det(A) · (A⁻¹)_ji (Jacobi's formula)
- **CPU backend**: LU decomposition via SciPy SuperLU (~0.3-0.8ms for n=10-1000)
- **CUDA backend**: torch.linalg.det for forward, torch.linalg.solve for gradient
- **Memory efficiency**: O(1) graph nodes via adjoint method (no iteration history)
- **Supported classes**: SparseTensor, DSparseTensor (with data gather warning)
- **Error handling**: NotImplementedError for DSparseMatrix (single partition)
- **Numerical considerations**: 
  - Determinant values overflow for large matrices (det → ±∞ for n > 1000)
  - Singular matrices cause LU decomposition to fail
  - Use float64 for better numerical stability
  - Gradient computation ~100x slower than forward-only (requires n linear solves)

**Performance Summary (from benchmarks/benchmark_determinant.py):**
```
Matrix Size | CPU (Sparse) | CUDA (Dense) | CPU-for-CUDA | Gradient | CUDA/CPU Ratio
------------|--------------|--------------|--------------|----------|----------------
n = 10      | 0.30 ms      | 0.96 ms      | 0.52 ms      | 3.5 ms   | 3.2x SLOWER
n = 100     | 0.30 ms      | 0.27 ms      | 0.54 ms      | 21 ms    | 0.9x (similar)
n = 500     | 0.45 ms      | 1.29 ms      | 0.82 ms      | 154 ms   | 2.9x SLOWER
n = 1000    | 0.71 ms      | 2.51 ms      | 1.20 ms      | 431 ms   | 3.6x SLOWER
```

**Key Findings:**
- ⚠️  **CUDA is SLOWER than CPU for sparse determinants!**
- CPU uses sparse LU (O(nnz^1.5)), CUDA requires dense conversion (O(n²) memory + O(n³) compute)
- CUDA is 1-3.6x slower than CPU across all matrix sizes
- **Recommendation**: Always use `.cpu().det()` for sparse matrices, even on CUDA
- Reason: cuSOLVER/cuDSS don't expose sparse determinant computation
- Gradient computation ~100x slower (requires n linear solves for (A^{-1})^T)
- Determinant values overflow for n > 1000

## Efficiency

- [ ] sparse matmul
  - [ ] cusparse backend
- [ ] sparse linear solve
  - [x] cudss backend
  - [x] torch backend
    - [x] cg
    - [x] bicgstab
    - [ ] gmres
    - [ ] minres
  - [x] torch distributed backend
- [x] sparse eigen vals
- [x] sparse determination