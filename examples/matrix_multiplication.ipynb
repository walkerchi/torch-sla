{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "Matrix Multiplication Examples for torch-sla\n",
        "\n",
        "This example demonstrates:\n",
        "1. Sparse @ Dense (vector and matrix)\n",
        "2. Dense @ Sparse (vector and matrix)  \n",
        "3. Sparse @ Sparse with sparse gradient\n",
        "4. Batched matrix multiplication\n",
        "5. CUDA matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import torch\n",
        "from torch_sla import SparseTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions and Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sparse_matrix(n: int, density: float = 0.1, dtype=torch.float64, device='cpu'):\n",
        "    \"\"\"Create random sparse matrix.\"\"\"\n",
        "    nnz = int(n * n * density)\n",
        "    row = torch.randint(0, n, (nnz,), device=device)\n",
        "    col = torch.randint(0, n, (nnz,), device=device)\n",
        "    val = torch.randn(nnz, dtype=dtype, device=device)\n",
        "    return SparseTensor(val, row, col, (n, n))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 Sparse Dense\n",
        "\n",
        "Sparse @ Dense multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 100\n",
        "A = create_sparse_matrix(n, density=0.05)\n",
        "A_dense = A.to_dense()\n",
        "\n",
        "print(f\"Sparse matrix: {A}\")\n",
        "print(f\"Sparsity: {1 - A.nnz / (n * n):.1%}\")\n",
        "\n",
        "# Sparse @ Dense vector\n",
        "x = torch.randn(n, dtype=torch.float64)\n",
        "y = A @ x\n",
        "y_expected = A_dense @ x\n",
        "print(f\"\\nSparse @ Dense vector:\")\n",
        "print(f\"  Input shape: {x.shape}\")\n",
        "print(f\"  Output shape: {y.shape}\")\n",
        "print(f\"  Correct: {torch.allclose(y, y_expected)}\")\n",
        "\n",
        "# Sparse @ Dense matrix\n",
        "X = torch.randn(n, 50, dtype=torch.float64)\n",
        "Y = A @ X\n",
        "Y_expected = A_dense @ X\n",
        "print(f\"\\nSparse @ Dense matrix:\")\n",
        "print(f\"  Input shape: {X.shape}\")\n",
        "print(f\"  Output shape: {Y.shape}\")\n",
        "print(f\"  Correct: {torch.allclose(Y, Y_expected)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 Dense Sparse\n",
        "\n",
        "Dense @ Sparse multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 100\n",
        "A = create_sparse_matrix(n, density=0.05)\n",
        "A_dense = A.to_dense()\n",
        "\n",
        "# Dense @ Sparse vector (row vector @ matrix)\n",
        "x = torch.randn(n, dtype=torch.float64)\n",
        "y = x @ A\n",
        "y_expected = x @ A_dense\n",
        "print(f\"Dense vector @ Sparse:\")\n",
        "print(f\"  Input shape: {x.shape}\")\n",
        "print(f\"  Output shape: {y.shape}\")\n",
        "print(f\"  Correct: {torch.allclose(y, y_expected)}\")\n",
        "\n",
        "# Dense @ Sparse matrix\n",
        "X = torch.randn(50, n, dtype=torch.float64)\n",
        "Y = X @ A\n",
        "Y_expected = X @ A_dense\n",
        "print(f\"\\nDense matrix @ Sparse:\")\n",
        "print(f\"  Input shape: {X.shape}\")\n",
        "print(f\"  Output shape: {Y.shape}\")\n",
        "print(f\"  Correct: {torch.allclose(Y, Y_expected)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Sparse Sparse\n",
        "\n",
        "Sparse @ Sparse multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 50\n",
        "A = create_sparse_matrix(n, density=0.1)\n",
        "B = create_sparse_matrix(n, density=0.1)\n",
        "\n",
        "A_dense = A.to_dense()\n",
        "B_dense = B.to_dense()\n",
        "\n",
        "# Sparse @ Sparse\n",
        "C = A @ B\n",
        "C_expected = A_dense @ B_dense\n",
        "\n",
        "print(f\"A: {A}\")\n",
        "print(f\"B: {B}\")\n",
        "print(f\"C = A @ B: {C}\")\n",
        "print(f\"Correct: {torch.allclose(C.to_dense(), C_expected, atol=1e-6)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 Sparse Gradient\n",
        "\n",
        "Sparse @ Sparse with sparse gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create matrices with gradient tracking\n",
        "val_a = torch.randn(100, dtype=torch.float64, requires_grad=True)\n",
        "row_a = torch.randint(0, 20, (100,))\n",
        "col_a = torch.randint(0, 20, (100,))\n",
        "A = SparseTensor(val_a, row_a, col_a, (20, 20))\n",
        "\n",
        "val_b = torch.randn(80, dtype=torch.float64, requires_grad=True)\n",
        "row_b = torch.randint(0, 20, (80,))\n",
        "col_b = torch.randint(0, 20, (80,))\n",
        "B = SparseTensor(val_b, row_b, col_b, (20, 20))\n",
        "\n",
        "print(f\"A: nnz={A.nnz}, val_a.shape={val_a.shape}\")\n",
        "print(f\"B: nnz={B.nnz}, val_b.shape={val_b.shape}\")\n",
        "\n",
        "# Forward\n",
        "C = A @ B\n",
        "loss = C.to_dense().sum()\n",
        "\n",
        "# Backward\n",
        "loss.backward()\n",
        "\n",
        "print(f\"\\nAfter backward:\")\n",
        "print(f\"  val_a.grad.shape: {val_a.grad.shape} (SPARSE - same as input!)\")\n",
        "print(f\"  val_b.grad.shape: {val_b.grad.shape} (SPARSE - same as input!)\")\n",
        "\n",
        "# Memory comparison\n",
        "n = 20\n",
        "dense_grad_size = n * n * 8  # bytes\n",
        "sparse_a_size = val_a.numel() * 8\n",
        "sparse_b_size = val_b.numel() * 8\n",
        "\n",
        "print(f\"\\nMemory comparison:\")\n",
        "print(f\"  Dense gradient would be: {dense_grad_size} bytes per matrix\")\n",
        "print(f\"  Sparse gradient A: {sparse_a_size} bytes\")\n",
        "print(f\"  Sparse gradient B: {sparse_b_size} bytes\")\n",
        "print(f\"  Savings: {dense_grad_size / sparse_a_size:.1f}x for A, {dense_grad_size / sparse_b_size:.1f}x for B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Batched Matmul\n",
        "\n",
        "Batched matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 50\n",
        "batch_size = 8\n",
        "\n",
        "# Create batched sparse matrix\n",
        "val = torch.randn(200, dtype=torch.float64)\n",
        "row = torch.randint(0, n, (200,))\n",
        "col = torch.randint(0, n, (200,))\n",
        "\n",
        "val_batch = val.unsqueeze(0).expand(batch_size, -1).clone()\n",
        "A_batch = SparseTensor(val_batch, row, col, (batch_size, n, n))\n",
        "\n",
        "print(f\"Batched SparseTensor: {A_batch}\")\n",
        "\n",
        "# Batched Sparse @ Dense vector\n",
        "x_batch = torch.randn(batch_size, n, dtype=torch.float64)\n",
        "y_batch = A_batch @ x_batch\n",
        "print(f\"\\nBatched Sparse @ Dense vector:\")\n",
        "print(f\"  Input: {x_batch.shape}\")\n",
        "print(f\"  Output: {y_batch.shape}\")\n",
        "\n",
        "# Batched Dense @ Sparse\n",
        "y_batch = x_batch @ A_batch\n",
        "print(f\"\\nBatched Dense @ Sparse:\")\n",
        "print(f\"  Input: {x_batch.shape}\")\n",
        "print(f\"  Output: {y_batch.shape}\")\n",
        "\n",
        "# Batched Sparse @ Dense matrix\n",
        "X_batch = torch.randn(batch_size, n, 20, dtype=torch.float64)\n",
        "Y_batch = A_batch @ X_batch\n",
        "print(f\"\\nBatched Sparse @ Dense matrix:\")\n",
        "print(f\"  Input: {X_batch.shape}\")\n",
        "print(f\"  Output: {Y_batch.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 Cuda Matmul\n",
        "\n",
        "CUDA matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA not available, skipping...\")\n",
        "    pass  # skipped in notebook\n",
        "\n",
        "n = 500\n",
        "\n",
        "# Create sparse matrix on CUDA\n",
        "val = torch.randn(5000, dtype=torch.float64, device='cuda')\n",
        "row = torch.randint(0, n, (5000,), device='cuda')\n",
        "col = torch.randint(0, n, (5000,), device='cuda')\n",
        "A = SparseTensor(val, row, col, (n, n))\n",
        "\n",
        "print(f\"CUDA SparseTensor: {A}\")\n",
        "\n",
        "# Time Sparse @ Dense\n",
        "x = torch.randn(n, dtype=torch.float64, device='cuda')\n",
        "\n",
        "# Warmup\n",
        "torch.cuda.synchronize()\n",
        "for _ in range(10):\n",
        "    y = A @ x\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# Benchmark\n",
        "import time\n",
        "N = 100\n",
        "torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(N):\n",
        "    y = A @ x\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "print(f\"\\nSparse @ Dense vector ({N} iterations):\")\n",
        "print(f\"  Time per iteration: {(t1-t0)/N*1000:.3f} ms\")\n",
        "\n",
        "# Sparse @ Dense matrix\n",
        "X = torch.randn(n, 100, dtype=torch.float64, device='cuda')\n",
        "torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(N):\n",
        "    Y = A @ X\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "print(f\"\\nSparse @ Dense matrix (100 cols, {N} iterations):\")\n",
        "print(f\"  Time per iteration: {(t1-t0)/N*1000:.3f} ms\")\n",
        "\n",
        "# Sparse @ Sparse\n",
        "B = SparseTensor(val.clone(), row.clone(), col.clone(), (n, n))\n",
        "torch.cuda.synchronize()\n",
        "t0 = time.time()\n",
        "for _ in range(N):\n",
        "    C = A @ B\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "print(f\"\\nSparse @ Sparse ({N} iterations):\")\n",
        "print(f\"  Time per iteration: {(t1-t0)/N*1000:.3f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7 Performance Comparison\n",
        "\n",
        "Performance comparison: scatter vs CSR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "n = 2000\n",
        "density = 0.005\n",
        "nnz = int(n * n * density)\n",
        "\n",
        "val = torch.randn(nnz, dtype=torch.float64)\n",
        "row = torch.randint(0, n, (nnz,))\n",
        "col = torch.randint(0, n, (nnz,))\n",
        "\n",
        "A = SparseTensor(val, row, col, (n, n))\n",
        "x = torch.randn(n, dtype=torch.float64)\n",
        "\n",
        "print(f\"Matrix: {n}x{n}, nnz={nnz}\")\n",
        "\n",
        "# Warmup\n",
        "for _ in range(5):\n",
        "    y = A @ x\n",
        "\n",
        "# Benchmark SparseTensor (scatter-based)\n",
        "N = 100\n",
        "t0 = time.time()\n",
        "for _ in range(N):\n",
        "    y = A @ x\n",
        "t1 = time.time()\n",
        "scatter_time = (t1 - t0) / N * 1000\n",
        "\n",
        "# Benchmark torch CSR\n",
        "A_csr = A.to_csr()\n",
        "for _ in range(5):\n",
        "    y_csr = torch.mv(A_csr, x)\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(N):\n",
        "    y_csr = torch.mv(A_csr, x)\n",
        "t1 = time.time()\n",
        "csr_time = (t1 - t0) / N * 1000\n",
        "\n",
        "print(f\"\\nCPU SpMV time:\")\n",
        "print(f\"  SparseTensor (scatter): {scatter_time:.3f} ms\")\n",
        "print(f\"  torch CSR (mv):         {csr_time:.3f} ms\")\n",
        "print(f\"  Correct: {torch.allclose(y, y_csr)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}