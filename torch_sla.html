<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html"><link rel="search" title="Search" href="search.html"><link rel="next" title="Examples" href="examples.html"><link rel="prev" title="Installation" href="installation.html">
        <link rel="canonical" href="https://walkerchi.github.io/torch-sla/torch_sla.html">
        <link rel="prefetch" href="_static/logo.jpg" as="image">

    <link rel="shortcut icon" href="_static/logo.jpg"><!-- Generated with Sphinx 7.4.7 and Furo 2025.12.19 -->
        <title>API Reference - torch-sla: PyTorch Sparse Linear Algebra | GPU Accelerated</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=69152257" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">torch-sla: PyTorch Sparse Linear Algebra | GPU Accelerated</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="_static/logo.jpg" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">torch-sla: PyTorch Sparse Linear Algebra | GPU Accelerated</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Documentation:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">Benchmarks</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/torch_sla.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="api-reference">
<h1>API Reference<a class="headerlink" href="#api-reference" title="Link to this heading">¶</a></h1>
<p>This section provides the core API documentation for torch-sla.</p>
<ul class="feature-list">
  <li><span class="gradient-text">SparseTensor</span>: Core class for 2D sparse matrices with full PyTorch autograd support</li>
  <li><span class="gradient-text">SparseTensorList</span>: Container for batched sparse matrices with different layouts</li>
  <li><span class="gradient-text">DSparseTensor</span>: Distributed sparse tensor with domain decomposition and halo exchange</li>
</ul><hr class="docutils" />
<section id="sparsetensor">
<h2>SparseTensor<a class="headerlink" href="#sparsetensor" title="Link to this heading">¶</a></h2>
<p>The main class for working with sparse matrices.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_sla.SparseTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_sla.</span></span><span class="sig-name descname"><span class="pre">SparseTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(-2,</span> <span class="pre">-1)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Wrapper class for PyTorch sparse tensors with batched and block support.</p>
<p>Supports tensors with shape […batch, M, N, …block] where:
- Leading dimensions […batch] are batch dimensions
- (M, N) are the sparse matrix dimensions (at sparse_dim positions)
- Trailing dimensions […block] are block dimensions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – Non-zero values with shape:
- Simple: [nnz]
- Batched: […batch, nnz]
- Block: [nnz, <a href="#id1"><span class="problematic" id="id2">*</span></a>block_shape]
- Batched+Block: […batch, nnz, <a href="#id3"><span class="problematic" id="id4">*</span></a>block_shape]</p></li>
<li><p><strong>row_indices</strong> (<em>torch.Tensor</em>) – Row indices with shape [nnz]. Must be on the same device as values.</p></li>
<li><p><strong>col_indices</strong> (<em>torch.Tensor</em>) – Column indices with shape [nnz]. Must be on the same device as values.</p></li>
<li><p><strong>shape</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>...</em><em>]</em>) – Full tensor shape […batch, M, N, <a href="#id5"><span class="problematic" id="id6">*</span></a>block_shape].</p></li>
<li><p><strong>sparse_dim</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Which dimensions are sparse (M, N). Default: (-2, -1) meaning last two
before any block dimensions.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.values">
<span class="sig-name descname"><span class="pre">values</span></span><a class="headerlink" href="#torch_sla.SparseTensor.values" title="Link to this definition">¶</a></dt>
<dd><p>The non-zero values.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.row_indices">
<span class="sig-name descname"><span class="pre">row_indices</span></span><a class="headerlink" href="#torch_sla.SparseTensor.row_indices" title="Link to this definition">¶</a></dt>
<dd><p>Row indices of non-zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.col_indices">
<span class="sig-name descname"><span class="pre">col_indices</span></span><a class="headerlink" href="#torch_sla.SparseTensor.col_indices" title="Link to this definition">¶</a></dt>
<dd><p>Column indices of non-zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.shape">
<span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#torch_sla.SparseTensor.shape" title="Link to this definition">¶</a></dt>
<dd><p>Full tensor shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)">int</a>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sparse_shape">
<span class="sig-name descname"><span class="pre">sparse_shape</span></span><a class="headerlink" href="#torch_sla.SparseTensor.sparse_shape" title="Link to this definition">¶</a></dt>
<dd><p>The (M, N) dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)">int</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.batch_shape">
<span class="sig-name descname"><span class="pre">batch_shape</span></span><a class="headerlink" href="#torch_sla.SparseTensor.batch_shape" title="Link to this definition">¶</a></dt>
<dd><p>The batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)">int</a>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.block_shape">
<span class="sig-name descname"><span class="pre">block_shape</span></span><a class="headerlink" href="#torch_sla.SparseTensor.block_shape" title="Link to this definition">¶</a></dt>
<dd><p>The block dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)">int</a>, …]</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p><strong>1. Simple 2D Sparse Matrix [M, N]</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torch_sla</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparseTensor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a 3x3 tridiagonal matrix in COO format</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">col</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">SparseTensor(shape=(3, 3), sparse=(3, 3), nnz=7, dtype=torch.float64, device=cpu)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Solve Ax = b</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>2. Batched Sparse Matrices [B, M, N]</strong></p>
<p>Same sparsity pattern, different values for each batch.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4 matrices, each 3x3, same structure</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val_batch</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># [4, 7]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">val_batch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span>  <span class="c1"># Scale each matrix</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_batch</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>  <span class="c1"># (4,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_batch</span><span class="o">.</span><span class="n">sparse_shape</span><span class="p">)</span>  <span class="c1"># (3, 3)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batched solve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_batch</span> <span class="o">=</span> <span class="n">A_batch</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b_batch</span><span class="p">)</span>  <span class="c1"># [4, 3]</span>
</pre></div>
</div>
<p><strong>3. Multi-Dimensional Batch [B1, B2, M, N]</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">B1</span><span class="p">,</span> <span class="n">B2</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span>  <span class="c1"># e.g., 2 materials x 3 temperatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val_batch</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B1</span><span class="p">,</span> <span class="n">B2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># [2, 3, 7]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_multi</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="n">B1</span><span class="p">,</span> <span class="n">B2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_multi</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>  <span class="c1"># (2, 3)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_multi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">B1</span><span class="p">,</span> <span class="n">B2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_multi</span> <span class="o">=</span> <span class="n">A_multi</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b_multi</span><span class="p">)</span>  <span class="c1"># [2, 3, 3]</span>
</pre></div>
</div>
<p><strong>4. Block Sparse Matrix [M, N, K, K] (Block Size K)</strong></p>
<p>Each non-zero entry is a KxK dense block instead of a scalar.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2x2 block matrix with 2x2 blocks = 4x4 total</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nnz</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># 3 non-zero blocks</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Values: [nnz, K, K] = [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nnz</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">row_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># Block row indices</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">col_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># Block col indices</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Shape: (num_block_rows, num_block_cols, block_size, block_size)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_block</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_block</span><span class="p">,</span> <span class="n">row_block</span><span class="p">,</span> <span class="n">col_block</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_block</span><span class="o">.</span><span class="n">block_shape</span><span class="p">)</span>  <span class="c1"># (2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_block</span><span class="o">.</span><span class="n">sparse_shape</span><span class="p">)</span>  <span class="c1"># (2, 2) - number of blocks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_block</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (2, 2, 2, 2) - full shape</span>
</pre></div>
</div>
<p><strong>5. Batched Block Sparse [B, M, N, K, K]</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val_batch_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">nnz</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>  <span class="c1"># [4, 3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch_block</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch_block</span><span class="p">,</span> <span class="n">row_block</span><span class="p">,</span> <span class="n">col_block</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_batch_block</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>  <span class="c1"># (4,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_batch_block</span><span class="o">.</span><span class="n">block_shape</span><span class="p">)</span>  <span class="c1"># (2, 2)</span>
</pre></div>
</div>
<p><strong>6. Create from Dense Matrix</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_dense</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_dense</span><span class="p">[</span><span class="n">A_dense</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Sparsify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="o">.</span><span class="n">from_dense</span><span class="p">(</span><span class="n">A_dense</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>7. Create from PyTorch Sparse Tensor</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="o">.</span><span class="n">from_torch_sparse</span><span class="p">(</span><span class="n">A_torch</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>8. Property Detection</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">is_symmetric</span><span class="p">()</span>  <span class="c1"># tensor(True) - returns tensor for batch support</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">is_positive_definite</span><span class="p">()</span>  <span class="c1"># tensor(True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">is_positive_definite</span><span class="p">(</span><span class="s1">&#39;cholesky&#39;</span><span class="p">)</span>  <span class="c1"># Use Cholesky factorization check</span>
</pre></div>
</div>
<p><strong>9. Matrix Operations</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Matrix-vector multiply</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">x</span>  <span class="c1"># SparseTensor @ dense vector</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Sparse-sparse multiply (returns SparseTensor with sparse gradients)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">A</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Norms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="s1">&#39;fro&#39;</span><span class="p">)</span>  <span class="c1"># Frobenius norm</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Eigenvalues (symmetric matrices)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;LM&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>10. CUDA Support</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_cuda</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">A_cuda</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>  <span class="c1"># Uses cuDSS or cuSOLVER</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.from_dense">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(-2,</span> <span class="pre">-1)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.from_dense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.from_dense" title="Link to this definition">¶</a></dt>
<dd><p>Create SparseTensor from dense tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>torch.Tensor</em>) – Dense tensor with shape […batch, M, N, …block].</p></li>
<li><p><strong>sparse_dim</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Which dimensions are sparse. Default: (-2, -1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sparse representation of A.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_dense</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_dense</span><span class="p">[</span><span class="n">A_dense</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="o">.</span><span class="n">from_dense</span><span class="p">(</span><span class="n">A_dense</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.from_torch_sparse">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_torch_sparse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.from_torch_sparse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.from_torch_sparse" title="Link to this definition">¶</a></dt>
<dd><p>Create SparseTensor from PyTorch sparse tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>A</strong> (<em>torch.Tensor</em>) – PyTorch sparse COO or CSR tensor (2D only).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SparseTensor representation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_coo</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="o">.</span><span class="n">from_torch_sparse</span><span class="p">(</span><span class="n">A_coo</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id0">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#id0" title="Link to this definition">¶</a></dt>
<dd><p>Full tensor shape […batch, M, N, …block].</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id7">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sparse_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#id7" title="Link to this definition">¶</a></dt>
<dd><p>The (M, N) sparse matrix dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id8">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#id8" title="Link to this definition">¶</a></dt>
<dd><p>The batch dimensions before the sparse dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id9">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">block_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#id9" title="Link to this definition">¶</a></dt>
<dd><p>The block dimensions after the sparse dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sparse_dim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sparse_dim</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torch_sla.SparseTensor.sparse_dim" title="Link to this definition">¶</a></dt>
<dd><p>The dimensions that are sparse (M, N).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.ndim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ndim</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.ndim" title="Link to this definition">¶</a></dt>
<dd><p>Number of dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.nnz">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nnz</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.nnz" title="Link to this definition">¶</a></dt>
<dd><p>Number of non-zero elements (per batch/block).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#torch_sla.SparseTensor.dtype" title="Link to this definition">¶</a></dt>
<dd><p>Data type of the values.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#torch_sla.SparseTensor.device" title="Link to this definition">¶</a></dt>
<dd><p>Device of the tensor.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.is_cuda">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_cuda</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.is_cuda" title="Link to this definition">¶</a></dt>
<dd><p>Whether the tensor is on CUDA.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.is_batched">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_batched</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.is_batched" title="Link to this definition">¶</a></dt>
<dd><p>Whether the tensor has batch dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.is_block">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_block</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.is_block" title="Link to this definition">¶</a></dt>
<dd><p>Whether the tensor has block dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.batch_size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.batch_size" title="Link to this definition">¶</a></dt>
<dd><p>Total number of batch elements (product of batch_shape).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.is_square">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_square</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.is_square" title="Link to this definition">¶</a></dt>
<dd><p>Whether the sparse dimensions are square (M == N).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.to" title="Link to this definition">¶</a></dt>
<dd><p>Move tensor to device and/or convert dtype.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em><em>, </em><em>optional</em>) – Target device (e.g., ‘cuda’, ‘cpu’, ‘cuda:0’).</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em><em>, </em><em>optional</em>) – Target data type (e.g., torch.float32, torch.float64).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>New SparseTensor on the target device/dtype.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_cuda</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_float32</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_cuda_float32</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.cuda"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.cuda" title="Link to this definition">¶</a></dt>
<dd><p>Move tensor to CUDA device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – CUDA device index. Default: current device.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor on CUDA.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.cpu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.cpu" title="Link to this definition">¶</a></dt>
<dd><p>Move tensor to CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor on CPU.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.float" title="Link to this definition">¶</a></dt>
<dd><p>Convert to float32.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.double"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.double" title="Link to this definition">¶</a></dt>
<dd><p>Convert to float64.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.half"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.half" title="Link to this definition">¶</a></dt>
<dd><p>Convert to float16.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.to_torch_sparse">
<span class="sig-name descname"><span class="pre">to_torch_sparse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.to_torch_sparse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.to_torch_sparse" title="Link to this definition">¶</a></dt>
<dd><p>Convert to PyTorch sparse COO tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_idx</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – For batched tensors, which batch element to convert.
Default: (0, 0, …) for first batch element.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PyTorch sparse COO tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.to_dense">
<span class="sig-name descname"><span class="pre">to_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.to_dense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.to_dense" title="Link to this definition">¶</a></dt>
<dd><p>Convert to dense tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_idx</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – For batched tensors, which batch element to convert.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dense tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.to_csr">
<span class="sig-name descname"><span class="pre">to_csr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.to_csr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.to_csr" title="Link to this definition">¶</a></dt>
<dd><p>Convert to CSR format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_idx</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – For batched tensors, which batch element to convert.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PyTorch sparse CSR tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.partition">
<span class="sig-name descname"><span class="pre">partition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_partitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.partition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.partition" title="Link to this definition">¶</a></dt>
<dd><p>Partition into a distributed sparse tensor.</p>
<p>Creates a DSparseTensor with automatic domain decomposition.
This is useful for distributed computing and parallel solvers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_partitions</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of partitions to create</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning [num_nodes, dim].
Required for ‘rcb’ and ‘slicing’ methods.</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Partitioning method:
- ‘auto’: Auto-select (uses ‘rcb’ if coords provided, else ‘metis’)
- ‘metis’: Graph-based partitioning (requires pymetis)
- ‘rcb’: Recursive Coordinate Bisection (requires coords)
- ‘slicing’: Simple coordinate slicing (requires coords)
- ‘simple’: Simple 1D partitioning by node index</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to print partition info</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Distributed sparse tensor with the specified partitions</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor">DSparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">partition</span> <span class="o">=</span> <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">partition</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">x_local</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Use <cite>D.to_sparse_tensor()</cite> to gather back to a SparseTensor</p></li>
<li><p>For distributed training, use <cite>partition_for_rank()</cite> instead</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.partition_for_rank">
<span class="sig-name descname"><span class="pre">partition_for_rank</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">world_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'simple'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DSparseMatrix</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.partition_for_rank"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.partition_for_rank" title="Link to this definition">¶</a></dt>
<dd><p>Get partition for a specific rank in distributed environment.</p>
<p>This is the recommended API for multi-process distributed computing.
Each rank calls this method with its own rank ID to get its local
partition. The partitioning is deterministic and consistent across
all ranks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rank</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – This process’s rank (0 to world_size-1)</p></li>
<li><p><strong>world_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Total number of processes</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Partitioning method (‘simple’, ‘metis’, ‘rcb’, ‘slicing’)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Print partition info</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Local partition for this rank</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DSparseMatrix</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># In multi-process code:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">partition</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">partition_for_rank</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_local</span> <span class="o">=</span> <span class="n">partition</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">x_local</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>This uses <cite>DSparseTensor.from_global_distributed()</cite> internally,
which broadcasts partition IDs from rank 0 for consistency.</p></li>
<li><p>Requires <cite>torch.distributed</cite> to be initialized.</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.T">
<span class="sig-name descname"><span class="pre">T</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.T"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.T" title="Link to this definition">¶</a></dt>
<dd><p>Transpose the sparse dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Transposed tensor with row/col indices swapped.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.flatten_blocks">
<span class="sig-name descname"><span class="pre">flatten_blocks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.flatten_blocks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.flatten_blocks" title="Link to this definition">¶</a></dt>
<dd><p>Flatten block dimensions into the sparse (M, N) dimensions.</p>
<p>For a block-sparse tensor with shape […batch, M, N, <a href="#id10"><span class="problematic" id="id11">*</span></a>block_shape],
this creates a new tensor with shape […batch, M*block_M, N*block_N]
where each block entry becomes multiple scalar entries.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Flattened tensor without block dimensions.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Block sparse: shape (10, 10, 2, 2), block_shape=(2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_flat</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">flatten_blocks</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (20, 20)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_flat</span><span class="o">.</span><span class="n">nnz</span><span class="p">)</span>    <span class="c1"># nnz * 4 (each block has 4 elements)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Only works for 2D block shapes (block_M, block_N).</p></li>
<li><p>Use <cite>unflatten_blocks(block_shape)</cite> to reverse this operation.</p></li>
<li><p>The flattened tensor’s sparsity pattern may have duplicates that
need to be coalesced.</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.unflatten_blocks">
<span class="sig-name descname"><span class="pre">unflatten_blocks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.unflatten_blocks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.unflatten_blocks" title="Link to this definition">¶</a></dt>
<dd><p>Restore block structure from a flattened tensor.</p>
<p>This is the inverse of <cite>flatten_blocks()</cite>. It groups scalar entries
back into block entries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>block_shape</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em>) – The (block_M, block_N) dimensions to create.
M and N must be divisible by block_M and block_N respectively.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Block-sparse tensor with the specified block shape.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_flat</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_block</span> <span class="o">=</span> <span class="n">A_flat</span><span class="o">.</span><span class="n">unflatten_blocks</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_block</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (10, 10, 2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A_block</span><span class="o">.</span><span class="n">block_shape</span><span class="p">)</span>  <span class="c1"># (2, 2)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Requires that the sparsity pattern is block-aligned.</p></li>
<li><p>All block entries must be present (dense within each block).</p></li>
<li><p>For sparse blocks, use <cite>to_block_sparse()</cite> instead.</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.is_symmetric">
<span class="sig-name descname"><span class="pre">is_symmetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_recompute</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.is_symmetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.is_symmetric" title="Link to this definition">¶</a></dt>
<dd><p>Check if the matrix is symmetric (A == A^T).</p>
<p>For batched tensors, checks each matrix independently and returns
a boolean tensor with shape matching the batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Absolute tolerance for comparison. Default: 1e-8.</p></li>
<li><p><strong>rtol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Relative tolerance for comparison. Default: 1e-5.</p></li>
<li><p><strong>force_recompute</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, recompute even if cached. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Boolean tensor with shape:
- [] (scalar) for non-batched tensors
- [<a href="#id12"><span class="problematic" id="id13">*</span></a>batch_shape] for batched tensors</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">is_symmetric</span><span class="p">()</span>  <span class="c1"># tensor(True) or tensor(False)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span><span class="o">.</span><span class="n">is_symmetric</span><span class="p">()</span>  <span class="c1"># tensor([True, True, True, True])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.is_positive_definite">
<span class="sig-name descname"><span class="pre">is_positive_definite</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'gershgorin'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cholesky'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eigenvalue'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gershgorin'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_recompute</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.is_positive_definite"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.is_positive_definite" title="Link to this definition">¶</a></dt>
<dd><p>Check if the matrix is positive definite.</p>
<p>For batched tensors, checks each matrix independently and returns
a boolean tensor with shape matching the batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<em>{&quot;gershgorin&quot;</em><em>, </em><em>&quot;cholesky&quot;</em><em>, </em><em>&quot;eigenvalue&quot;}</em><em>, </em><em>optional</em>) – Method for checking:
- “gershgorin”: Fast check using Gershgorin circles (sufficient but not necessary)
- “cholesky”: Try Cholesky decomposition (necessary and sufficient, slower)
- “eigenvalue”: Check smallest eigenvalues (necessary and sufficient, slowest)
Default: “gershgorin”.</p></li>
<li><p><strong>force_recompute</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, recompute even if cached. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Boolean tensor with shape:
- [] (scalar) for non-batched tensors
- [<a href="#id14"><span class="problematic" id="id15">*</span></a>batch_shape] for batched tensors</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">is_positive_definite</span><span class="p">()</span>  <span class="c1"># tensor(True) or tensor(False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">is_positive_definite</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;cholesky&quot;</span><span class="p">)</span>  <span class="c1"># More accurate check</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span><span class="o">.</span><span class="n">is_positive_definite</span><span class="p">()</span>  <span class="c1"># tensor([True, True, True, True])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.solve">
<span class="sig-name descname"><span class="pre">solve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'scipy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eigen'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'pytorch'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cusolver'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cudss'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'auto'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'auto'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'superlu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'umfpack'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'qr'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cholesky'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ldlt'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cg'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'bicgstab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'gmres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lgmres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'minres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'qmr'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.solve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.solve" title="Link to this definition">¶</a></dt>
<dd><p>Solve the sparse linear system Ax = b.</p>
<p>Automatically handles batched tensors: if A is […batch, M, N] and
b is […batch, M], returns x with shape […batch, N].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>torch.Tensor</em>) – Right-hand side vector(s). Shape:
- Non-batched: [M] or [M, K] for multiple RHS
- Batched: […batch, M] or […batch, M, K]</p></li>
<li><p><strong>backend</strong> (<em>{&quot;auto&quot;</em><em>, </em><em>&quot;scipy&quot;</em><em>, </em><em>&quot;eigen&quot;</em><em>, </em><em>&quot;cusolver&quot;</em><em>, </em><em>&quot;cudss&quot;}</em><em>, </em><em>optional</em>) – Solver backend. Default: “auto” (selects based on device).
- “scipy”: Uses SciPy’s sparse solvers (CPU only)
- “eigen”: Uses Eigen C++ library (CPU only)
- “cusolver”: Uses NVIDIA cuSOLVER (CUDA only)
- “cudss”: Uses NVIDIA cuDSS (CUDA only)</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Solver method. Default: “auto” (selects based on matrix properties).
- Direct methods: “superlu”, “umfpack”, “lu”, “qr”, “cholesky”, “ldlt”
- Iterative methods: “cg”, “bicgstab”, “gmres”, “minres”</p></li>
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Absolute tolerance for iterative solvers. Default: 1e-10.</p></li>
<li><p><strong>maxiter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum iterations for iterative solvers. Default: 10000.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Relative tolerance for direct solvers. Default: 1e-12.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Solution x with same batch shape as b.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.14)"><strong>ValueError</strong></a> – If matrix is not square.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.14)"><strong>NotImplementedError</strong></a> – If block sparse tensors are used (not yet supported).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simple solve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batched solve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_batch</span> <span class="o">=</span> <span class="n">A_batch</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b_batch</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Specify backend</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;scipy&#39;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;cg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.solve_batch">
<span class="sig-name descname"><span class="pre">solve_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'scipy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eigen'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'pytorch'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cusolver'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cudss'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'auto'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'auto'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'superlu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'umfpack'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'qr'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cholesky'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ldlt'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cg'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'bicgstab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'gmres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lgmres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'minres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'qmr'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.solve_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.solve_batch" title="Link to this definition">¶</a></dt>
<dd><p>Solve with different values but same sparsity structure.</p>
<p>This is efficient when you have the same structure but different values
(e.g., time-stepping, optimization, parameter sweeps).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – Matrix values. Shape […batch, nnz] where … are batch dimensions.
All matrices share the same row_indices and col_indices.</p></li>
<li><p><strong>b</strong> (<em>torch.Tensor</em>) – Right-hand side. Shape […batch, M].</p></li>
<li><p><strong>backend</strong> (<em>{&quot;auto&quot;</em><em>, </em><em>&quot;scipy&quot;</em><em>, </em><em>&quot;eigen&quot;</em><em>, </em><em>&quot;cusolver&quot;</em><em>, </em><em>&quot;cudss&quot;}</em><em>, </em><em>optional</em>) – Solver backend. See solve() for details. Default: “auto”.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Solver method. See solve() for details. Default: “auto”.</p></li>
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Absolute tolerance for iterative solvers. Default: 1e-10.</p></li>
<li><p><strong>maxiter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum iterations for iterative solvers. Default: 10000.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Relative tolerance. Default: 1e-12.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Solution x with shape […batch, N].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Template matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batch of different values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">val</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)])</span>  <span class="c1"># [4, nnz]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Solve all at once</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_batch</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">solve_batch</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">b_batch</span><span class="p">)</span>  <span class="c1"># [4, 10]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.nonlinear_solve">
<span class="sig-name descname"><span class="pre">nonlinear_solve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">residual_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'newton'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'picard'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'anderson'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'newton'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'scipy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eigen'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'pytorch'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cusolver'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cudss'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'auto'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'pytorch'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'auto'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'superlu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'umfpack'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'qr'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cholesky'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'ldlt'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cg'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'bicgstab'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'gmres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'lgmres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'minres'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'qmr'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cg'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.nonlinear_solve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.nonlinear_solve" title="Link to this definition">¶</a></dt>
<dd><p>Solve nonlinear equation F(u, A, θ) = 0 with adjoint-based gradients.</p>
<p>The SparseTensor A is automatically passed as the first parameter to
the residual function, enabling gradients to flow through A’s values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>residual_fn</strong> (<em>Callable</em>) – Function F(u, A, <a href="#id16"><span class="problematic" id="id17">*</span></a>params) -&gt; residual tensor.
- u: Current solution estimate
- A: This SparseTensor (passed automatically)
- <a href="#id18"><span class="problematic" id="id19">*</span></a>params: Additional parameters with requires_grad=True</p></li>
<li><p><strong>u0</strong> (<em>torch.Tensor</em>) – Initial guess for solution.</p></li>
<li><p><strong>*params</strong> (<em>torch.Tensor</em>) – Additional parameters (e.g., boundary conditions, coefficients).
Tensors with requires_grad=True will receive gradients.</p></li>
<li><p><strong>method</strong> (<em>{'newton'</em><em>, </em><em>'picard'</em><em>, </em><em>'anderson'}</em><em>, </em><em>optional</em>) – Nonlinear solver method:
- ‘newton’: Newton-Raphson with line search (default, fast)
- ‘picard’: Fixed-point iteration (simple, slow)
- ‘anderson’: Anderson acceleration (memory efficient)</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Relative convergence tolerance. Default: 1e-6.</p></li>
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Absolute convergence tolerance. Default: 1e-10.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum nonlinear iterations. Default: 50.</p></li>
<li><p><strong>line_search</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Use Armijo line search for Newton. Default: True.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Print convergence information. Default: False.</p></li>
<li><p><strong>linear_solver</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Backend for linear solves. Default: ‘pytorch’.</p></li>
<li><p><strong>linear_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Method for linear solves. Default: ‘cg’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Solution u* satisfying F(u*, A, θ) ≈ 0.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Nonlinear PDE: A @ u + u² = f</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">residual</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">A</span> <span class="o">@</span> <span class="n">u</span> <span class="o">+</span> <span class="n">u</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">f</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">nonlinear_solve</span><span class="p">(</span><span class="n">residual</span><span class="p">,</span> <span class="n">u0</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;newton&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Gradients flow via adjoint method</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>  <span class="c1"># ∂u/∂f</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>  <span class="c1"># ∂u/∂A (if A.values.requires_grad)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Nonlinear elasticity: K(u) @ u = F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">residual_elasticity</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">material</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># K depends on displacement through material nonlinearity</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">K</span> <span class="o">@</span> <span class="n">u</span> <span class="o">-</span> <span class="n">F</span> <span class="o">+</span> <span class="n">material</span> <span class="o">*</span> <span class="n">u</span><span class="o">**</span><span class="mi">3</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">nonlinear_solve</span><span class="p">(</span><span class="n">residual_elasticity</span><span class="p">,</span> <span class="n">u0</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">material</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.norm">
<span class="sig-name descname"><span class="pre">norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ord</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'fro'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="m"><span class="pre">1</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="m"><span class="pre">2</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fro'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.norm" title="Link to this definition">¶</a></dt>
<dd><p>Compute matrix norm.</p>
<p>For batched tensors, returns norm for each batch element.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ord</strong> (<em>{'fro'</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>optional</em>) – Norm type:
- ‘fro’: Frobenius norm (default)
- 1: Maximum absolute column sum
- 2: Spectral norm (largest singular value)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Norm value(s). Shape [] for non-batched, [<a href="#id20"><span class="problematic" id="id21">*</span></a>batch_shape] for batched.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="s1">&#39;fro&#39;</span><span class="p">)</span>  <span class="c1"># tensor(5.0)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="s1">&#39;fro&#39;</span><span class="p">)</span>  <span class="c1"># tensor([5.0, 5.0, 5.0, 5.0])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.spy">
<span class="sig-name descname"><span class="pre">spy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'viridis'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_grid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_color</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'#cccccc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_linewidth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_colorbar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(8,</span> <span class="pre">8)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dpi</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">150</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.spy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.spy" title="Link to this definition">¶</a></dt>
<dd><p>Visualize the sparsity pattern with values shown as color intensity.</p>
<p>Creates a spy plot where each matrix element is rendered as a pixel.
Non-zero elements are colored with intensity proportional to the absolute
value, while zero elements are shown as white. This provides a pixel-perfect
visualization without overlapping markers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_idx</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – For batched tensors, which batch element to visualize.
Required if the tensor is batched.</p></li>
<li><p><strong>ax</strong> (<em>matplotlib.axes.Axes</em><em>, </em><em>optional</em>) – Axes to plot on. If None, creates a new figure.</p></li>
<li><p><strong>title</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Plot title. Defaults to showing matrix info.</p></li>
<li><p><strong>cmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Colormap for values. Default: ‘viridis’.
Other options: ‘plasma’, ‘hot’, ‘coolwarm’, ‘Greys’, etc.</p></li>
<li><p><strong>show_grid</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to show grid lines (only for matrices &lt;= 30x30). Default: True.</p></li>
<li><p><strong>grid_color</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Color of grid lines. Default: ‘#cccccc’ (light gray).</p></li>
<li><p><strong>grid_linewidth</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Width of grid lines. Default: 0.5.</p></li>
<li><p><strong>show_colorbar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to show colorbar for values. Default: True.</p></li>
<li><p><strong>figsize</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>]</em><em>, </em><em>optional</em>) – Figure size in inches. Default: (8, 8).</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – If provided, save figure to this path.</p></li>
<li><p><strong>dpi</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – DPI for saved figure. Default: 150.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ax</strong> – The axes object with the plot.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>matplotlib.axes.Axes</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">spy</span><span class="p">()</span>  <span class="c1"># Basic spy plot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">spy</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;hot&#39;</span><span class="p">,</span> <span class="n">show_grid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Custom colormap, no grid</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">spy</span><span class="p">(</span><span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;matrix.png&#39;</span><span class="p">)</span>  <span class="c1"># Save to file</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># For batched tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val_batch</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_batch</span><span class="o">.</span><span class="n">spy</span><span class="p">(</span><span class="n">batch_idx</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>  <span class="c1"># Visualize first batch element</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.eigs">
<span class="sig-name descname"><span class="pre">eigs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'LM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_eigenvectors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.eigs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.eigs" title="Link to this definition">¶</a></dt>
<dd><p>Compute k eigenvalues and eigenvectors.</p>
<p>For batched tensors, computes for each batch element.
For CUDA tensors, uses LOBPCG algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of eigenvalues to compute. Default: 6.</p></li>
<li><p><strong>which</strong> (<em>{&quot;LM&quot;</em><em>, </em><em>&quot;SM&quot;</em><em>, </em><em>&quot;LR&quot;</em><em>, </em><em>&quot;SR&quot;</em><em>, </em><em>&quot;LA&quot;</em><em>, </em><em>&quot;SA&quot;}</em><em>, </em><em>optional</em>) – Which eigenvalues to find:
- “LM”: Largest magnitude (default)
- “SM”: Smallest magnitude
- “LR”/”SR”: Largest/smallest real part
- “LA”/”SA”: Largest/smallest algebraic (for symmetric)</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Find eigenvalues near sigma (shift-invert mode).</p></li>
<li><p><strong>return_eigenvectors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to return eigenvectors. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>eigenvalues</strong> (<em>torch.Tensor</em>) – Shape [k] for non-batched, [<a href="#id22"><span class="problematic" id="id23">*</span></a>batch_shape, k] for batched.</p></li>
<li><p><strong>eigenvectors</strong> (<em>torch.Tensor or None</em>) – Shape [M, k] for non-batched, [<a href="#id24"><span class="problematic" id="id25">*</span></a>batch_shape, M, k] for batched.
None if return_eigenvectors is False.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><strong>Gradient Support:</strong></p>
<ul class="simple">
<li><p>Both CPU and CUDA: Fully differentiable via adjoint method</p></li>
<li><p>Uses O(1) graph nodes regardless of iteration count</p></li>
<li><p>For symmetric matrices, prefer eigsh() for efficiency</p></li>
</ul>
<p><strong>Warning</strong>: For non-symmetric matrices with complex eigenvalues,
gradient computation is only supported for the real part.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">eigs</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">eigenvalues</span><span class="o">.</span><span class="n">real</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># For complex eigenvalues</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.eigsh">
<span class="sig-name descname"><span class="pre">eigsh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'LM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_eigenvectors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.eigsh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.eigsh" title="Link to this definition">¶</a></dt>
<dd><p>Compute k eigenvalues for symmetric matrices.</p>
<p>More efficient than eigs() for symmetric matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of eigenvalues to compute. Default: 6.</p></li>
<li><p><strong>which</strong> (<em>{&quot;LM&quot;</em><em>, </em><em>&quot;SM&quot;</em><em>, </em><em>&quot;LA&quot;</em><em>, </em><em>&quot;SA&quot;}</em><em>, </em><em>optional</em>) – Which eigenvalues to find:
- “LM”: Largest magnitude (default)
- “SM”: Smallest magnitude
- “LA”/”SA”: Largest/smallest algebraic</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Find eigenvalues near sigma.</p></li>
<li><p><strong>return_eigenvectors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to return eigenvectors. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>eigenvalues</strong> (<em>torch.Tensor</em>) – Shape [k] for non-batched, [<a href="#id26"><span class="problematic" id="id27">*</span></a>batch_shape, k] for batched.</p></li>
<li><p><strong>eigenvectors</strong> (<em>torch.Tensor or None</em>) – Shape [M, k] for non-batched, [<a href="#id28"><span class="problematic" id="id29">*</span></a>batch_shape, M, k] for batched.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><strong>Gradient Support:</strong></p>
<ul class="simple">
<li><p>Both CPU and CUDA: Fully differentiable via adjoint method</p></li>
<li><p>Uses O(1) graph nodes regardless of iteration count</p></li>
<li><p>Gradient computed as: ∂L/∂A = Σ_i (∂L/∂λ_i) * v_i &#64; v_i.T</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">eigenvalues</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Computes ∂loss/∂val</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.svd">
<span class="sig-name descname"><span class="pre">svd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.svd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.svd" title="Link to this definition">¶</a></dt>
<dd><p>Compute truncated SVD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of singular values to compute. Default: 6.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>U</strong> (<em>torch.Tensor</em>) – Left singular vectors. Shape [M, k] or [<a href="#id30"><span class="problematic" id="id31">*</span></a>batch_shape, M, k].</p></li>
<li><p><strong>S</strong> (<em>torch.Tensor</em>) – Singular values. Shape [k] or [<a href="#id32"><span class="problematic" id="id33">*</span></a>batch_shape, k].</p></li>
<li><p><strong>Vt</strong> (<em>torch.Tensor</em>) – Right singular vectors. Shape [k, N] or [<a href="#id34"><span class="problematic" id="id35">*</span></a>batch_shape, k, N].</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><strong>Gradient Support:</strong></p>
<ul class="simple">
<li><p>CUDA: Fully differentiable (uses power iteration with PyTorch operations)</p></li>
<li><p>CPU: NOT differentiable (uses SciPy which breaks gradient chain)</p></li>
</ul>
<p>For differentiable SVD on CPU, use <cite>A.to_dense()</cite> and <cite>torch.linalg.svd()</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.condition_number">
<span class="sig-name descname"><span class="pre">condition_number</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ord</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.condition_number"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.condition_number" title="Link to this definition">¶</a></dt>
<dd><p>Estimate condition number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ord</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Norm order for condition number. Default: 2 (spectral).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Condition number. Shape [] or [<a href="#id36"><span class="problematic" id="id37">*</span></a>batch_shape].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.lu">
<span class="sig-name descname"><span class="pre">lu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LUFactorization</span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.lu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.lu" title="Link to this definition">¶</a></dt>
<dd><p>Compute LU decomposition for repeated solves.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Factorization object with solve() method.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>LUFactorization</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lu</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">lu</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">lu</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">lu</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>  <span class="c1"># Reuses factorization</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sum">
<span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.sum" title="Link to this definition">¶</a></dt>
<dd><p>Sum of sparse tensor elements over specified axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em> of </em><em>ints</em><em>, or </em><em>None</em>) – <p>Axis or axes along which to sum. Axes correspond to:
- Batch dimensions: […batch] at the beginning
- Sparse dimensions: (M, N) at sparse_dim positions
- Block dimensions: […block] at the end</p>
<p>If None, sum over all elements (returns scalar tensor).</p>
</p></li>
<li><p><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to keep the reduced dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>If reducing over sparse dimensions: returns dense tensor</p></li>
<li><p>If reducing over batch/block dimensions only: returns SparseTensor</p></li>
<li><p>If axis=None: returns scalar tensor</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor or <a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Shape: [batch=2, M=10, N=10, block=3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>           <span class="c1"># Scalar: sum all elements</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>     <span class="c1"># Sum over batch -&gt; [10, 10, 3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># Sum over M (rows) -&gt; [2, 10, 3] (dense)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>     <span class="c1"># Sum over N (cols) -&gt; [2, 10, 3] (dense)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>     <span class="c1"># Sum over block -&gt; SparseTensor [2, 10, 10]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="c1"># Sum over M and N -&gt; [2, 3] (dense)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.mean" title="Link to this definition">¶</a></dt>
<dd><p>Mean of sparse tensor elements over specified axis.</p>
<p>Note: For sparse dimensions, this computes mean of non-zero values only,
NOT the mean over all M*N elements. For full mean, use to_dense().mean().</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em> of </em><em>ints</em><em>, or </em><em>None</em>) – Axis or axes along which to compute mean.</p></li>
<li><p><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to keep the reduced dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mean values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor or <a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>           <span class="c1"># Mean of all non-zero values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>     <span class="c1"># Mean over batch dimension</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.prod">
<span class="sig-name descname"><span class="pre">prod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.prod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.prod" title="Link to this definition">¶</a></dt>
<dd><p>Product of sparse tensor elements over specified axis.</p>
<p>Warning: For sparse matrices, zero elements are not included in the product.
This means prod() computes the product of non-zero values only.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em> of </em><em>ints</em><em>, or </em><em>None</em>) – Axis or axes along which to compute product.</p></li>
<li><p><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to keep the reduced dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Product values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor or <a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>           <span class="c1"># Product of all non-zero values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>     <span class="c1"># Product over batch dimension</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.max">
<span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.max"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.max" title="Link to this definition">¶</a></dt>
<dd><p>Max of non-zero values over specified axis.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.min">
<span class="sig-name descname"><span class="pre">min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.min"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.min" title="Link to this definition">¶</a></dt>
<dd><p>Min of non-zero values over specified axis.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.abs">
<span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.abs" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise absolute value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sqrt">
<span class="sig-name descname"><span class="pre">sqrt</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.sqrt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.sqrt" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise square root.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.square">
<span class="sig-name descname"><span class="pre">square</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.square"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.square" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise square.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.exp">
<span class="sig-name descname"><span class="pre">exp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.exp" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise exponential.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.log" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise natural logarithm.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.log10">
<span class="sig-name descname"><span class="pre">log10</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.log10"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.log10" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise base-10 logarithm.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.log2">
<span class="sig-name descname"><span class="pre">log2</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.log2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.log2" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise base-2 logarithm.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sin">
<span class="sig-name descname"><span class="pre">sin</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.sin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.sin" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise sine.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.cos">
<span class="sig-name descname"><span class="pre">cos</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.cos"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.cos" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise cosine.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.tan">
<span class="sig-name descname"><span class="pre">tan</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.tan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.tan" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise tangent.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sinh">
<span class="sig-name descname"><span class="pre">sinh</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.sinh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.sinh" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise hyperbolic sine.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.cosh">
<span class="sig-name descname"><span class="pre">cosh</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.cosh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.cosh" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise hyperbolic cosine.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.tanh">
<span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.tanh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.tanh" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise hyperbolic tangent.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sigmoid">
<span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.sigmoid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.sigmoid" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise sigmoid.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.relu">
<span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.relu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.relu" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise ReLU.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">min</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.clamp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.clamp" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise clamp.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.sign">
<span class="sig-name descname"><span class="pre">sign</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.sign"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.sign" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise sign.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.floor">
<span class="sig-name descname"><span class="pre">floor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.floor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.floor" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise floor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.ceil">
<span class="sig-name descname"><span class="pre">ceil</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.ceil"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.ceil" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise ceil.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.round">
<span class="sig-name descname"><span class="pre">round</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.round"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.round" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise round.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.reciprocal">
<span class="sig-name descname"><span class="pre">reciprocal</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.reciprocal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.reciprocal" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise reciprocal (1/x).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.pow">
<span class="sig-name descname"><span class="pre">pow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">exponent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.pow"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.pow" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise power.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.logical_not">
<span class="sig-name descname"><span class="pre">logical_not</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.logical_not"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.logical_not" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise logical NOT.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.logical_and">
<span class="sig-name descname"><span class="pre">logical_and</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.logical_and"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.logical_and" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise logical AND.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.logical_or">
<span class="sig-name descname"><span class="pre">logical_or</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.logical_or"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.logical_or" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise logical OR.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.logical_xor">
<span class="sig-name descname"><span class="pre">logical_xor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.logical_xor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.logical_xor" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise logical XOR.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.isnan">
<span class="sig-name descname"><span class="pre">isnan</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.isnan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.isnan" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise isnan check.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.isinf">
<span class="sig-name descname"><span class="pre">isinf</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.isinf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.isinf" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise isinf check.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.isfinite">
<span class="sig-name descname"><span class="pre">isfinite</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.isfinite"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.isfinite" title="Link to this definition">¶</a></dt>
<dd><p>Element-wise isfinite check.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.detach">
<span class="sig-name descname"><span class="pre">detach</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.detach"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.detach" title="Link to this definition">¶</a></dt>
<dd><p>Detach from computation graph.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.requires_grad_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.requires_grad_" title="Link to this definition">¶</a></dt>
<dd><p>Enable/disable gradient tracking.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.requires_grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">requires_grad</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.requires_grad" title="Link to this definition">¶</a></dt>
<dd><p>Whether gradient tracking is enabled.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">grad</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></em><a class="headerlink" href="#torch_sla.SparseTensor.grad" title="Link to this definition">¶</a></dt>
<dd><p>Gradient of values if available.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.clone" title="Link to this definition">¶</a></dt>
<dd><p>Create a copy of this SparseTensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.contiguous">
<span class="sig-name descname"><span class="pre">contiguous</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.contiguous"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.contiguous" title="Link to this definition">¶</a></dt>
<dd><p>Make values contiguous in memory.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/os.html#os.PathLike" title="(in Python v3.14)"><span class="pre">PathLike</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.14)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.save" title="Link to this definition">¶</a></dt>
<dd><p>Save SparseTensor to safetensors format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>PathLike</em>) – Output file path (should end with .safetensors).</p></li>
<li><p><strong>metadata</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a><em>, </em><em>optional</em>) – Additional metadata to store.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;matrix.safetensors&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/os.html#os.PathLike" title="(in Python v3.14)"><span class="pre">PathLike</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.load" title="Link to this definition">¶</a></dt>
<dd><p>Load SparseTensor from safetensors format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>PathLike</em>) – Input file path.</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em>) – Device to load tensors to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The loaded sparse tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;matrix.safetensors&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensor.save_distributed">
<span class="sig-name descname"><span class="pre">save_distributed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/os.html#os.PathLike" title="(in Python v3.14)"><span class="pre">PathLike</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_partitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'simple'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensor.save_distributed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensor.save_distributed" title="Link to this definition">¶</a></dt>
<dd><p>Save as partitioned files for distributed loading.</p>
<p>Creates a directory with metadata and per-partition files.
Each rank can then load only its own partition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>PathLike</em>) – Output directory path.</p></li>
<li><p><strong>num_partitions</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of partitions to create.</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – ‘simple’, ‘metis’, or ‘geometric’.</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Print progress.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">save_distributed</span><span class="p">(</span><span class="s2">&quot;matrix_dist&quot;</span><span class="p">,</span> <span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="go"># Each rank loads its partition:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">partition</span> <span class="o">=</span> <span class="n">DSparseMatrix</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;matrix_dist&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="sparsetensorlist">
<h2>SparseTensorList<a class="headerlink" href="#sparsetensorlist" title="Link to this heading">¶</a></h2>
<p>Container for multiple sparse matrices with different layouts.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_sla.</span></span><span class="sig-name descname"><span class="pre">SparseTensorList</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.sparse_tensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A list of SparseTensors with different structures.</p>
<p>Provides a unified interface for batch operations on matrices
with different sparsity patterns. Unlike batched SparseTensor
(which requires same structure), SparseTensorList allows
each matrix to have different shape and sparsity pattern.</p>
<blockquote>
<div></div></blockquote>
<dl class="simple">
<dt>tensors<span class="classifier">List[SparseTensor]</span></dt><dd><p>List of SparseTensor objects.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.shapes">
<span class="sig-name descname"><span class="pre">shapes</span></span><a class="headerlink" href="#torch_sla.SparseTensorList.shapes" title="Link to this definition">¶</a></dt>
<dd><p>List of shapes for each tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tuple[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)">int</a>, …]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#torch_sla.SparseTensorList.device" title="Link to this definition">¶</a></dt>
<dd><p>Device (from first tensor).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.dtype">
<span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#torch_sla.SparseTensorList.dtype" title="Link to this definition">¶</a></dt>
<dd><p>Data type (from first tensor).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.dtype</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create matrices with different sizes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A1</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val1</span><span class="p">,</span> <span class="n">row1</span><span class="p">,</span> <span class="n">col1</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A2</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val2</span><span class="p">,</span> <span class="n">row2</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A3</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val3</span><span class="p">,</span> <span class="n">row3</span><span class="p">,</span> <span class="n">col3</span><span class="p">,</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create list</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matrices</span> <span class="o">=</span> <span class="n">SparseTensorList</span><span class="p">([</span><span class="n">A1</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">A3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">matrices</span><span class="o">.</span><span class="n">shapes</span><span class="p">)</span>  <span class="c1"># [(10, 10), (20, 20), (30, 30)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batch solve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_list</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span><span class="p">])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Check properties for all</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_sym</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">is_symmetric</span><span class="p">()</span>  <span class="c1"># [tensor(True), tensor(True), tensor(True)]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.from_coo_list">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_coo_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matrices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.sparse_tensor.SparseTensorList"><span class="pre">SparseTensorList</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.from_coo_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.from_coo_list" title="Link to this definition">¶</a></dt>
<dd><p>Create from list of COO data tuples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>matrices</strong> (<em>List</em><em>[</em><em>Tuple</em><em>]</em>) – List of (values, row_indices, col_indices, shape) tuples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of SparseTensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.SparseTensorList">SparseTensorList</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="p">(</span><span class="n">val1</span><span class="p">,</span> <span class="n">row1</span><span class="p">,</span> <span class="n">col1</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span>
<span class="gp">... </span>    <span class="p">(</span><span class="n">val2</span><span class="p">,</span> <span class="n">row2</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)),</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matrices</span> <span class="o">=</span> <span class="n">SparseTensorList</span><span class="o">.</span><span class="n">from_coo_list</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.from_torch_sparse_list">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_torch_sparse_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.sparse_tensor.SparseTensorList"><span class="pre">SparseTensorList</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.from_torch_sparse_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.from_torch_sparse_list" title="Link to this definition">¶</a></dt>
<dd><p>Create from list of PyTorch sparse tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>A_list</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of PyTorch sparse COO tensors.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of SparseTensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.SparseTensorList">SparseTensorList</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id38">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shapes</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#id38" title="Link to this definition">¶</a></dt>
<dd><p>List of shapes for each tensor.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id39">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#id39" title="Link to this definition">¶</a></dt>
<dd><p>Device of the first tensor.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id40">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#id40" title="Link to this definition">¶</a></dt>
<dd><p>Data type of the first tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.sparse_tensor.SparseTensorList"><span class="pre">SparseTensorList</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.to" title="Link to this definition">¶</a></dt>
<dd><p>Move all tensors to device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em>) – Target device.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>New list with tensors on target device.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.SparseTensorList">SparseTensorList</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.sparse_tensor.SparseTensorList"><span class="pre">SparseTensorList</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.cuda"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.cuda" title="Link to this definition">¶</a></dt>
<dd><p>Move all tensors to CUDA.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensorList" title="torch_sla.sparse_tensor.SparseTensorList"><span class="pre">SparseTensorList</span></a></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.cpu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.cpu" title="Link to this definition">¶</a></dt>
<dd><p>Move all tensors to CPU.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.solve">
<span class="sig-name descname"><span class="pre">solve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.solve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.solve" title="Link to this definition">¶</a></dt>
<dd><p>Solve linear systems for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b_list</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of right-hand side vectors, one per matrix.</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments passed to SparseTensor.solve().</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of solutions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">matrices</span> <span class="o">=</span> <span class="n">SparseTensorList</span><span class="p">([</span><span class="n">A1</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">A3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_list</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">solve</span><span class="p">([</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.is_symmetric">
<span class="sig-name descname"><span class="pre">is_symmetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.is_symmetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.is_symmetric" title="Link to this definition">¶</a></dt>
<dd><p>Check symmetry for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> – Arguments passed to SparseTensor.is_symmetric().</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of boolean tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.is_positive_definite">
<span class="sig-name descname"><span class="pre">is_positive_definite</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.is_positive_definite"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.is_positive_definite" title="Link to this definition">¶</a></dt>
<dd><p>Check positive definiteness for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> – Arguments passed to SparseTensor.is_positive_definite().</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of boolean tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.norm">
<span class="sig-name descname"><span class="pre">norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ord</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'fro'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="m"><span class="pre">1</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="m"><span class="pre">2</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fro'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.norm" title="Link to this definition">¶</a></dt>
<dd><p>Compute norms for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ord</strong> (<em>{'fro'</em><em>, </em><em>1</em><em>, </em><em>2}</em>) – Norm type.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of norm values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.eigs">
<span class="sig-name descname"><span class="pre">eigs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.eigs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.eigs" title="Link to this definition">¶</a></dt>
<dd><p>Compute eigenvalues for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of eigenvalues.</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of (eigenvalues, eigenvectors) tuples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tuple[torch.Tensor, Optional[torch.Tensor]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.eigsh">
<span class="sig-name descname"><span class="pre">eigsh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.eigsh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.eigsh" title="Link to this definition">¶</a></dt>
<dd><p>Compute eigenvalues for symmetric matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of eigenvalues.</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of (eigenvalues, eigenvectors) tuples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tuple[torch.Tensor, Optional[torch.Tensor]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.svd">
<span class="sig-name descname"><span class="pre">svd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.svd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.svd" title="Link to this definition">¶</a></dt>
<dd><p>Compute SVD for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of singular values.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of (U, S, Vt) tuples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tuple[torch.Tensor, torch.Tensor, torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.condition_number">
<span class="sig-name descname"><span class="pre">condition_number</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ord</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.condition_number"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.condition_number" title="Link to this definition">¶</a></dt>
<dd><p>Compute condition numbers for all matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ord</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Norm order.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of condition numbers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.SparseTensorList.spy">
<span class="sig-name descname"><span class="pre">spy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ncols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/sparse_tensor.html#SparseTensorList.spy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.SparseTensorList.spy" title="Link to this definition">¶</a></dt>
<dd><p>Visualize sparsity patterns for multiple matrices in a grid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Which matrices to visualize. Default: all.</p></li>
<li><p><strong>ncols</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of columns in subplot grid. Default: 3.</p></li>
<li><p><strong>figsize</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>]</em><em>, </em><em>optional</em>) – Figure size. Auto-computed if None.</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments passed to SparseTensor.spy().</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>fig</strong> – The figure object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>matplotlib.figure.Figure</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">matrices</span> <span class="o">=</span> <span class="n">SparseTensorList</span><span class="p">([</span><span class="n">A1</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">A3</span><span class="p">,</span> <span class="n">A4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matrices</span><span class="o">.</span><span class="n">spy</span><span class="p">()</span>  <span class="c1"># Visualize all in grid</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matrices</span><span class="o">.</span><span class="n">spy</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># Visualize specific ones</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="dsparsetensor">
<h2>DSparseTensor<a class="headerlink" href="#dsparsetensor" title="Link to this heading">¶</a></h2>
<p>Distributed sparse tensor with domain decomposition support.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_sla.</span></span><span class="sig-name descname"><span class="pre">DSparseTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_partitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Distributed Sparse Tensor with automatic partitioning and halo exchange.</p>
<p>A Pythonic wrapper that provides a unified interface for distributed
sparse matrix operations. Supports indexing to access individual partitions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – Non-zero values [nnz]</p></li>
<li><p><strong>row_indices</strong> (<em>torch.Tensor</em>) – Row indices [nnz]</p></li>
<li><p><strong>col_indices</strong> (<em>torch.Tensor</em>) – Column indices [nnz]</p></li>
<li><p><strong>shape</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em>) – Matrix shape (m, n)</p></li>
<li><p><strong>num_partitions</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of partitions to create</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning [num_nodes, dim]</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Partitioning method: ‘metis’, ‘rcb’, ‘slicing’, ‘simple’</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em>) – Device for the matrix data</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to print partition info</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torch_sla</span><span class="w"> </span><span class="kn">import</span> <span class="n">DSparseTensor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create distributed tensor with 4 partitions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">DSparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Access individual partitions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A0</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># First partition</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A1</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Second partition</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Iterate over partitions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">partition</span> <span class="ow">in</span> <span class="n">A</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">x</span> <span class="o">=</span> <span class="n">partition</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b_local</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Properties</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">num_partitions</span><span class="p">)</span>  <span class="c1"># 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>           <span class="c1"># Global shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>            <span class="c1"># 4</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Move to CUDA</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_cuda</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Local halo exchange (for testing)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_local</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">halo_exchange_local</span><span class="p">(</span><span class="n">x_list</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.from_sparse_tensor">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_sparse_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparse_tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_partitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.from_sparse_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.from_sparse_tensor" title="Link to this definition">¶</a></dt>
<dd><p>Create DSparseTensor from a SparseTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_tensor</strong> (<a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor"><em>SparseTensor</em></a>) – Input sparse tensor (must be 2D, not batched)</p></li>
<li><p><strong>num_partitions</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Number of partitions</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Partitioning method</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em><em>, </em><em>optional</em>) – Target device (defaults to sparse_tensor’s device)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to print partition info</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Distributed sparse tensor</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor">DSparseTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.from_torch_sparse">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_torch_sparse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_partitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.distributed.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.from_torch_sparse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.from_torch_sparse" title="Link to this definition">¶</a></dt>
<dd><p>Create DSparseTensor from PyTorch sparse tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.from_global_distributed">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_global_distributed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">world_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DSparseMatrix</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.from_global_distributed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.from_global_distributed" title="Link to this definition">¶</a></dt>
<dd><p>Create local partition in a distributed-safe manner.</p>
<p>This method ensures that all ranks compute the same partition assignment
by having rank 0 compute the partition IDs and broadcasting to all ranks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – Global non-zero values [nnz]</p></li>
<li><p><strong>row_indices</strong> (<em>torch.Tensor</em>) – Global row indices [nnz]</p></li>
<li><p><strong>col_indices</strong> (<em>torch.Tensor</em>) – Global column indices [nnz]</p></li>
<li><p><strong>shape</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em>) – Global matrix shape (M, N)</p></li>
<li><p><strong>rank</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Current process rank</p></li>
<li><p><strong>world_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Total number of processes</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning [num_nodes, dim]</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Partitioning method: ‘metis’, ‘rcb’, ‘slicing’, ‘simple’</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em><em>, </em><em>optional</em>) – Target device</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to print partition info</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Local partition matrix for this rank</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DSparseMatrix</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In each process:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">local_matrix</span> <span class="o">=</span> <span class="n">DSparseTensor</span><span class="o">.</span><span class="n">from_global_distributed</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.from_device_mesh">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_device_mesh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_mesh</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeviceMesh</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'simple'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">placement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'shard_rows'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DSparseMatrix</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.from_device_mesh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.from_device_mesh" title="Link to this definition">¶</a></dt>
<dd><p>Create local partition using PyTorch DeviceMesh.</p>
<p>This is the recommended method for distributed training with PyTorch’s
DTensor ecosystem. Each rank receives only its local partition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – Global non-zero values [nnz] (same on all ranks)</p></li>
<li><p><strong>row_indices</strong> (<em>torch.Tensor</em>) – Global row indices [nnz]</p></li>
<li><p><strong>col_indices</strong> (<em>torch.Tensor</em>) – Global column indices [nnz]</p></li>
<li><p><strong>shape</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em>) – Global matrix shape (M, N)</p></li>
<li><p><strong>device_mesh</strong> (<em>DeviceMesh</em>) – PyTorch DeviceMesh specifying device topology</p></li>
<li><p><strong>coords</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Node coordinates for geometric partitioning</p></li>
<li><p><strong>partition_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Partitioning method: ‘metis’, ‘rcb’, ‘simple’
Default is ‘simple’ for determinism in distributed setting</p></li>
<li><p><strong>placement</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – How to distribute: ‘shard_rows’, ‘shard_cols’, ‘replicate’</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to print partition info</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Local partition for this rank</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DSparseMatrix</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.device_mesh</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_device_mesh</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">torch_sla</span><span class="w"> </span><span class="kn">import</span> <span class="n">DSparseTensor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initialize 4-GPU device mesh</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mesh</span> <span class="o">=</span> <span class="n">init_device_mesh</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,),</span> <span class="n">mesh_dim_names</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;dp&quot;</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create distributed sparse tensor (each rank gets its partition)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">local_matrix</span> <span class="o">=</span> <span class="n">DSparseTensor</span><span class="o">.</span><span class="n">from_device_mesh</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">device_mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">partition_method</span><span class="o">=</span><span class="s1">&#39;simple&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Local operations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_local</span> <span class="o">=</span> <span class="n">local_matrix</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">x_local</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_local</span> <span class="o">=</span> <span class="n">local_matrix</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b_local</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#torch_sla.DSparseTensor.shape" title="Link to this definition">¶</a></dt>
<dd><p>Global matrix shape.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.num_partitions">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_partitions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></em><a class="headerlink" href="#torch_sla.DSparseTensor.num_partitions" title="Link to this definition">¶</a></dt>
<dd><p>Number of partitions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#torch_sla.DSparseTensor.device" title="Link to this definition">¶</a></dt>
<dd><p>Device of the matrix data.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#torch_sla.DSparseTensor.dtype" title="Link to this definition">¶</a></dt>
<dd><p>Data type of matrix values.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.nnz">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nnz</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></em><a class="headerlink" href="#torch_sla.DSparseTensor.nnz" title="Link to this definition">¶</a></dt>
<dd><p>Total number of non-zeros.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.partition_ids">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">partition_ids</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#torch_sla.DSparseTensor.partition_ids" title="Link to this definition">¶</a></dt>
<dd><p>Partition assignment for each node.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.is_cuda">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_cuda</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></em><a class="headerlink" href="#torch_sla.DSparseTensor.is_cuda" title="Link to this definition">¶</a></dt>
<dd><p>Check if matrix is on CUDA.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.distributed.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.to" title="Link to this definition">¶</a></dt>
<dd><p>Move all partitions to a different device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em>) – Target device</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>New distributed tensor on target device</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor">DSparseTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.distributed.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.cuda"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.cuda" title="Link to this definition">¶</a></dt>
<dd><p>Move to CUDA device.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.distributed.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.cpu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.cpu" title="Link to this definition">¶</a></dt>
<dd><p>Move to CPU.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.halo_exchange_local">
<span class="sig-name descname"><span class="pre">halo_exchange_local</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.halo_exchange_local"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.halo_exchange_local" title="Link to this definition">¶</a></dt>
<dd><p>Local halo exchange for single-process simulation.</p>
<p>Exchanges halo values between all partitions locally.
Useful for testing without actual distributed setup.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x_list</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of local vectors, one per partition. Each vector is
modified in-place to update halo values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.matvec_all">
<span class="sig-name descname"><span class="pre">matvec_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exchange_halo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.matvec_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.matvec_all" title="Link to this definition">¶</a></dt>
<dd><p>Matrix-vector multiply on all partitions.</p>
<p>Performs y = A &#64; x for each partition, with optional halo exchange.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_list</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of local vectors, one per partition. Each vector should have
size = num_owned + num_halo for that partition.</p></li>
<li><p><strong>exchange_halo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Whether to perform halo exchange before multiplication.
Default True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of result vectors, one per partition. Each result has
size = num_owned (only owned nodes have valid results).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_local</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">scatter_local</span><span class="p">(</span><span class="n">x_global</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_local</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">matvec_all</span><span class="p">(</span><span class="n">x_local</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_global</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">gather_global</span><span class="p">(</span><span class="n">y_local</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.solve_all">
<span class="sig-name descname"><span class="pre">solve_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.solve_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.solve_all" title="Link to this definition">¶</a></dt>
<dd><p>Solve on all partitions (subdomain solves).</p>
<p>NOTE: This performs LOCAL subdomain solves, NOT a global distributed solve.
Each partition solves its own local system independently.
For a true distributed solve, use <cite>solve_distributed()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b_list</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of local RHS vectors, one per partition</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments passed to each partition’s solve method</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of solution vectors, one per partition</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.solve_distributed">
<span class="sig-name descname"><span class="pre">solve_distributed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b_global</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.solve_distributed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.solve_distributed" title="Link to this definition">¶</a></dt>
<dd><p>Distributed solve: find x such that A &#64; x = b using all partitions.</p>
<p>This performs a TRUE distributed solve where all partitions collaborate
to solve the global system. Uses distributed CG with global reductions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b_global</strong> (<em>torch.Tensor</em>) – Global RHS vector [N]</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – Solver method: ‘cg’ (Conjugate Gradient)</p></li>
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – Absolute tolerance for convergence</p></li>
<li><p><strong>maxiter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Maximum iterations</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Print convergence info</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Global solution vector [N]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">solve_distributed</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># Distributed CG solve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">residual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">x</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.gather_global">
<span class="sig-name descname"><span class="pre">gather_global</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.gather_global"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.gather_global" title="Link to this definition">¶</a></dt>
<dd><p>Gather local vectors to global vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x_list</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of local vectors, one per partition</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Global vector</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.scatter_local">
<span class="sig-name descname"><span class="pre">scatter_local</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_global</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.scatter_local"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.scatter_local" title="Link to this definition">¶</a></dt>
<dd><p>Scatter global vector to local vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x_global</strong> (<em>torch.Tensor</em>) – Global vector</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of local vectors (with halo values filled)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.to_sparse_tensor">
<span class="sig-name descname"><span class="pre">to_sparse_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.to_sparse_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.to_sparse_tensor" title="Link to this definition">¶</a></dt>
<dd><p>Gather all partitions into a single SparseTensor.</p>
<p>This creates a global SparseTensor from the distributed data.
Useful for verification, debugging, or when you need to perform
operations that require the full matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Global sparse tensor containing all data</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">DSparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">to_sparse_tensor</span><span class="p">()</span>  <span class="c1"># Gather to global SparseTensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># Solve on the full matrix</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.gather">
<span class="sig-name descname"><span class="pre">gather</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="headerlink" href="#torch_sla.DSparseTensor.gather" title="Link to this definition">¶</a></dt>
<dd><p>Gather all partitions into a single SparseTensor.</p>
<p>This creates a global SparseTensor from the distributed data.
Useful for verification, debugging, or when you need to perform
operations that require the full matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Global sparse tensor containing all data</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch_sla.SparseTensor" title="torch_sla.SparseTensor">SparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">DSparseTensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">to_sparse_tensor</span><span class="p">()</span>  <span class="c1"># Gather to global SparseTensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># Solve on the full matrix</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.eigsh">
<span class="sig-name descname"><span class="pre">eigsh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'LM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_eigenvectors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.eigsh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.eigsh" title="Link to this definition">¶</a></dt>
<dd><p>Compute k eigenvalues for symmetric matrices using distributed LOBPCG.</p>
<p>This is a TRUE distributed algorithm - no data gather required.
Uses distributed matvec with global QR decomposition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of eigenvalues to compute. Default: 6.</p></li>
<li><p><strong>which</strong> (<em>{&quot;LM&quot;</em><em>, </em><em>&quot;SM&quot;</em><em>, </em><em>&quot;LA&quot;</em><em>, </em><em>&quot;SA&quot;}</em><em>, </em><em>optional</em>) – Which eigenvalues to find:
- “LM”/”LA”: Largest (default)
- “SM”/”SA”: Smallest</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Find eigenvalues near sigma (not yet supported).</p></li>
<li><p><strong>return_eigenvectors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to return eigenvectors. Default: True.</p></li>
<li><p><strong>maxiter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum LOBPCG iterations. Default: 1000.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Convergence tolerance. Default: 1e-8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>eigenvalues</strong> (<em>torch.Tensor</em>) – Shape [k].</p></li>
<li><p><strong>eigenvectors</strong> (<em>torch.Tensor or None</em>) – Shape [N, k] if return_eigenvectors is True.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><strong>Distributed Algorithm:</strong></p>
<ul class="simple">
<li><p>Uses distributed LOBPCG (Locally Optimal Block PCG)</p></li>
<li><p>Only requires distributed matvec + global reductions</p></li>
<li><p>Memory: O(N * k) per node for eigenvectors</p></li>
<li><p>Communication: O(k^2) per iteration for Rayleigh-Ritz</p></li>
</ul>
<p><strong>Gradient Support:</strong></p>
<ul class="simple">
<li><p>Gradients flow through the distributed matvec operations</p></li>
<li><p>O(iterations) graph nodes (not O(1) like adjoint)</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.eigs">
<span class="sig-name descname"><span class="pre">eigs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'LM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_eigenvectors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.eigs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.eigs" title="Link to this definition">¶</a></dt>
<dd><p>Compute k eigenvalues using distributed LOBPCG.</p>
<p>For symmetric matrices, equivalent to eigsh().
For non-symmetric, currently falls back to eigsh() (symmetric assumption).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of eigenvalues to compute. Default: 6.</p></li>
<li><p><strong>which</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Which eigenvalues to find.</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Find eigenvalues near sigma.</p></li>
<li><p><strong>return_eigenvectors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to return eigenvectors. Default: True.</p></li>
<li><p><strong>maxiter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum iterations. Default: 1000.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Convergence tolerance. Default: 1e-8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>eigenvalues</strong> (<em>torch.Tensor</em>) – Shape [k].</p></li>
<li><p><strong>eigenvectors</strong> (<em>torch.Tensor or None</em>) – Shape [N, k] if return_eigenvectors is True.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.svd">
<span class="sig-name descname"><span class="pre">svd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.14)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.svd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.svd" title="Link to this definition">¶</a></dt>
<dd><p>Compute truncated SVD using distributed power iteration.</p>
<p>Uses A^T &#64; A for eigenvalues, then recovers U from A &#64; V.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Number of singular values to compute. Default: 6.</p></li>
<li><p><strong>maxiter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum iterations. Default: 1000.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – Convergence tolerance. Default: 1e-8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>U</strong> (<em>torch.Tensor</em>) – Left singular vectors. Shape [M, k].</p></li>
<li><p><strong>S</strong> (<em>torch.Tensor</em>) – Singular values. Shape [k].</p></li>
<li><p><strong>Vt</strong> (<em>torch.Tensor</em>) – Right singular vectors. Shape [k, N].</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><strong>Distributed Algorithm:</strong></p>
<ul class="simple">
<li><p>Computes eigenvalues of A^T &#64; A using distributed LOBPCG</p></li>
<li><p>No data gather required</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.norm">
<span class="sig-name descname"><span class="pre">norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ord</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(in Python v3.14)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'fro'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="m"><span class="pre">1</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="m"><span class="pre">2</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fro'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.norm" title="Link to this definition">¶</a></dt>
<dd><p>Compute matrix norm (distributed).</p>
<p>For Frobenius norm, computed locally and aggregated.
For spectral norm, uses distributed SVD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ord</strong> (<em>{'fro'</em><em>, </em><em>1</em><em>, </em><em>2}</em>) – Type of norm:
- ‘fro’: Frobenius norm (distributed sum)
- 1: Maximum column sum
- 2: Spectral norm (largest singular value via distributed SVD)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Scalar tensor containing the norm value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.condition_number">
<span class="sig-name descname"><span class="pre">condition_number</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ord</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.condition_number"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.condition_number" title="Link to this definition">¶</a></dt>
<dd><p>Estimate condition number using distributed SVD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ord</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – Norm order. Default: 2 (spectral).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Condition number estimate (σ_max / σ_min).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.T">
<span class="sig-name descname"><span class="pre">T</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.distributed.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.T"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.T" title="Link to this definition">¶</a></dt>
<dd><p>Transpose the distributed sparse tensor.</p>
<p>Returns a new DSparseTensor with swapped row/column indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Transposed matrix.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor">DSparseTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.to_dense">
<span class="sig-name descname"><span class="pre">to_dense</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.to_dense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.to_dense" title="Link to this definition">¶</a></dt>
<dd><p>Convert to dense tensor.</p>
<p>WARNING: This gathers all data to a single node.
Only use for small matrices or debugging.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dense matrix of shape (M, N).</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.is_symmetric">
<span class="sig-name descname"><span class="pre">is_symmetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.is_symmetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.is_symmetric" title="Link to this definition">¶</a></dt>
<dd><p>Check if matrix is symmetric.</p>
<p>Can be done distributedly by comparing values with transpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – Absolute tolerance for symmetry check.</p></li>
<li><p><strong>rtol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – Relative tolerance for symmetry check.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Boolean scalar tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.is_positive_definite">
<span class="sig-name descname"><span class="pre">is_positive_definite</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.is_positive_definite"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.is_positive_definite" title="Link to this definition">¶</a></dt>
<dd><p>Check if matrix is positive definite.</p>
<p>Uses distributed eigenvalue computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Boolean scalar tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.lu">
<span class="sig-name descname"><span class="pre">lu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.lu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.lu" title="Link to this definition">¶</a></dt>
<dd><p>Compute LU decomposition.</p>
<p>WARNING: LU is inherently not distributed-friendly.
This gathers data to a single node.</p>
<p>For distributed solves, use solve_distributed() with iterative methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Factorization object with solve() method.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>LUFactorization</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.spy">
<span class="sig-name descname"><span class="pre">spy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.spy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.spy" title="Link to this definition">¶</a></dt>
<dd><p>Visualize sparsity pattern.</p>
<p>Gathers data for visualization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> – Arguments passed to SparseTensor.spy().</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.nonlinear_solve">
<span class="sig-name descname"><span class="pre">nonlinear_solve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">residual_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'newton'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.nonlinear_solve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.nonlinear_solve" title="Link to this definition">¶</a></dt>
<dd><p>Solve nonlinear equation F(u, D, <a href="#id41"><span class="problematic" id="id42">*</span></a>params) = 0 using distributed Newton-Krylov.</p>
<p>Uses Jacobian-free Newton-Krylov with distributed CG for linear solves.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>residual_fn</strong> (<em>callable</em>) – Function F(u, D, <a href="#id43"><span class="problematic" id="id44">*</span></a>params) -&gt; residual tensor.
D is this DSparseTensor.</p></li>
<li><p><strong>u0</strong> (<em>torch.Tensor</em>) – Initial guess (global vector).</p></li>
<li><p><strong>*params</strong> (<em>torch.Tensor</em>) – Additional parameters.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – ‘newton’: Newton-Krylov with distributed CG
‘picard’: Fixed-point iteration</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – Relative tolerance.</p></li>
<li><p><strong>atol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – Absolute tolerance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – Maximum outer iterations.</p></li>
<li><p><strong>line_search</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Use Armijo line search.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Print convergence info.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Solution u such that F(u, D, <a href="#id45"><span class="problematic" id="id46">*</span></a>params) ≈ 0.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><strong>Distributed Algorithm:</strong></p>
<ul class="simple">
<li><p>Uses Jacobian-free Newton-Krylov (JFNK)</p></li>
<li><p>Linear solves use distributed CG</p></li>
<li><p>Jacobian-vector products computed via finite differences</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/os.html#os.PathLike" title="(in Python v3.14)"><span class="pre">PathLike</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.save" title="Link to this definition">¶</a></dt>
<dd><p>Save DSparseTensor to disk.</p>
<p>Creates a directory with metadata and per-partition files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>PathLike</em>) – Output directory.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – Print progress.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">num_partitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;matrix_dist&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_sla.DSparseTensor.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/os.html#os.PathLike" title="(in Python v3.14)"><span class="pre">PathLike</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">device</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.distributed.DSparseTensor"><span class="pre">DSparseTensor</span></a></span></span><a class="reference internal" href="_modules/torch_sla/distributed.html#DSparseTensor.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_sla.DSparseTensor.load" title="Link to this definition">¶</a></dt>
<dd><p>Load a complete DSparseTensor from disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>PathLike</em>) – Directory containing saved data.</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>torch.device</em>) – Device to load to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The loaded distributed sparse tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch_sla.DSparseTensor" title="torch_sla.DSparseTensor">DSparseTensor</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">DSparseTensor</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;matrix_dist&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="examples.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Examples</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="installation.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Installation</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, walker chi
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/walkerchi/torch-sla" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">API Reference</a><ul>
<li><a class="reference internal" href="#sparsetensor">SparseTensor</a><ul>
<li><a class="reference internal" href="#torch_sla.SparseTensor"><code class="docutils literal notranslate"><span class="pre">SparseTensor</span></code></a><ul>
<li><a class="reference internal" href="#torch_sla.SparseTensor.values"><code class="docutils literal notranslate"><span class="pre">SparseTensor.values</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.row_indices"><code class="docutils literal notranslate"><span class="pre">SparseTensor.row_indices</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.col_indices"><code class="docutils literal notranslate"><span class="pre">SparseTensor.col_indices</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.shape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.shape</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sparse_shape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sparse_shape</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.batch_shape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.batch_shape</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.block_shape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.block_shape</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.from_dense"><code class="docutils literal notranslate"><span class="pre">SparseTensor.from_dense()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.from_torch_sparse"><code class="docutils literal notranslate"><span class="pre">SparseTensor.from_torch_sparse()</span></code></a></li>
<li><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">SparseTensor.shape</span></code></a></li>
<li><a class="reference internal" href="#id7"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sparse_shape</span></code></a></li>
<li><a class="reference internal" href="#id8"><code class="docutils literal notranslate"><span class="pre">SparseTensor.batch_shape</span></code></a></li>
<li><a class="reference internal" href="#id9"><code class="docutils literal notranslate"><span class="pre">SparseTensor.block_shape</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sparse_dim"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sparse_dim</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.ndim"><code class="docutils literal notranslate"><span class="pre">SparseTensor.ndim</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.nnz"><code class="docutils literal notranslate"><span class="pre">SparseTensor.nnz</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.dtype"><code class="docutils literal notranslate"><span class="pre">SparseTensor.dtype</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.device"><code class="docutils literal notranslate"><span class="pre">SparseTensor.device</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.is_cuda"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_cuda</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.is_batched"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_batched</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.is_block"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_block</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.batch_size"><code class="docutils literal notranslate"><span class="pre">SparseTensor.batch_size</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.is_square"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_square</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.to"><code class="docutils literal notranslate"><span class="pre">SparseTensor.to()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.cuda"><code class="docutils literal notranslate"><span class="pre">SparseTensor.cuda()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.cpu"><code class="docutils literal notranslate"><span class="pre">SparseTensor.cpu()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.float"><code class="docutils literal notranslate"><span class="pre">SparseTensor.float()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.double"><code class="docutils literal notranslate"><span class="pre">SparseTensor.double()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.half"><code class="docutils literal notranslate"><span class="pre">SparseTensor.half()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.to_torch_sparse"><code class="docutils literal notranslate"><span class="pre">SparseTensor.to_torch_sparse()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.to_dense"><code class="docutils literal notranslate"><span class="pre">SparseTensor.to_dense()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.to_csr"><code class="docutils literal notranslate"><span class="pre">SparseTensor.to_csr()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.partition"><code class="docutils literal notranslate"><span class="pre">SparseTensor.partition()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.partition_for_rank"><code class="docutils literal notranslate"><span class="pre">SparseTensor.partition_for_rank()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.T"><code class="docutils literal notranslate"><span class="pre">SparseTensor.T()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.flatten_blocks"><code class="docutils literal notranslate"><span class="pre">SparseTensor.flatten_blocks()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.unflatten_blocks"><code class="docutils literal notranslate"><span class="pre">SparseTensor.unflatten_blocks()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.is_symmetric"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_symmetric()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.is_positive_definite"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_positive_definite()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.solve"><code class="docutils literal notranslate"><span class="pre">SparseTensor.solve()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.solve_batch"><code class="docutils literal notranslate"><span class="pre">SparseTensor.solve_batch()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.nonlinear_solve"><code class="docutils literal notranslate"><span class="pre">SparseTensor.nonlinear_solve()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.norm"><code class="docutils literal notranslate"><span class="pre">SparseTensor.norm()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.spy"><code class="docutils literal notranslate"><span class="pre">SparseTensor.spy()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.eigs"><code class="docutils literal notranslate"><span class="pre">SparseTensor.eigs()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.eigsh"><code class="docutils literal notranslate"><span class="pre">SparseTensor.eigsh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.svd"><code class="docutils literal notranslate"><span class="pre">SparseTensor.svd()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.condition_number"><code class="docutils literal notranslate"><span class="pre">SparseTensor.condition_number()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.lu"><code class="docutils literal notranslate"><span class="pre">SparseTensor.lu()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sum"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sum()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.mean"><code class="docutils literal notranslate"><span class="pre">SparseTensor.mean()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.prod"><code class="docutils literal notranslate"><span class="pre">SparseTensor.prod()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.max"><code class="docutils literal notranslate"><span class="pre">SparseTensor.max()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.min"><code class="docutils literal notranslate"><span class="pre">SparseTensor.min()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.abs"><code class="docutils literal notranslate"><span class="pre">SparseTensor.abs()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sqrt"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sqrt()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.square"><code class="docutils literal notranslate"><span class="pre">SparseTensor.square()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.exp"><code class="docutils literal notranslate"><span class="pre">SparseTensor.exp()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.log"><code class="docutils literal notranslate"><span class="pre">SparseTensor.log()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.log10"><code class="docutils literal notranslate"><span class="pre">SparseTensor.log10()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.log2"><code class="docutils literal notranslate"><span class="pre">SparseTensor.log2()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sin"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sin()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.cos"><code class="docutils literal notranslate"><span class="pre">SparseTensor.cos()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.tan"><code class="docutils literal notranslate"><span class="pre">SparseTensor.tan()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sinh"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sinh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.cosh"><code class="docutils literal notranslate"><span class="pre">SparseTensor.cosh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.tanh"><code class="docutils literal notranslate"><span class="pre">SparseTensor.tanh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sigmoid"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sigmoid()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.relu"><code class="docutils literal notranslate"><span class="pre">SparseTensor.relu()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.clamp"><code class="docutils literal notranslate"><span class="pre">SparseTensor.clamp()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.sign"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sign()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.floor"><code class="docutils literal notranslate"><span class="pre">SparseTensor.floor()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.ceil"><code class="docutils literal notranslate"><span class="pre">SparseTensor.ceil()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.round"><code class="docutils literal notranslate"><span class="pre">SparseTensor.round()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.reciprocal"><code class="docutils literal notranslate"><span class="pre">SparseTensor.reciprocal()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.pow"><code class="docutils literal notranslate"><span class="pre">SparseTensor.pow()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.logical_not"><code class="docutils literal notranslate"><span class="pre">SparseTensor.logical_not()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.logical_and"><code class="docutils literal notranslate"><span class="pre">SparseTensor.logical_and()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.logical_or"><code class="docutils literal notranslate"><span class="pre">SparseTensor.logical_or()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.logical_xor"><code class="docutils literal notranslate"><span class="pre">SparseTensor.logical_xor()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.isnan"><code class="docutils literal notranslate"><span class="pre">SparseTensor.isnan()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.isinf"><code class="docutils literal notranslate"><span class="pre">SparseTensor.isinf()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.isfinite"><code class="docutils literal notranslate"><span class="pre">SparseTensor.isfinite()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.detach"><code class="docutils literal notranslate"><span class="pre">SparseTensor.detach()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.requires_grad_"><code class="docutils literal notranslate"><span class="pre">SparseTensor.requires_grad_()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.requires_grad"><code class="docutils literal notranslate"><span class="pre">SparseTensor.requires_grad</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.grad"><code class="docutils literal notranslate"><span class="pre">SparseTensor.grad</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.clone"><code class="docutils literal notranslate"><span class="pre">SparseTensor.clone()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.contiguous"><code class="docutils literal notranslate"><span class="pre">SparseTensor.contiguous()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.save"><code class="docutils literal notranslate"><span class="pre">SparseTensor.save()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.load"><code class="docutils literal notranslate"><span class="pre">SparseTensor.load()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensor.save_distributed"><code class="docutils literal notranslate"><span class="pre">SparseTensor.save_distributed()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#sparsetensorlist">SparseTensorList</a><ul>
<li><a class="reference internal" href="#torch_sla.SparseTensorList"><code class="docutils literal notranslate"><span class="pre">SparseTensorList</span></code></a><ul>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.shapes"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.shapes</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.device"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.device</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.dtype"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.dtype</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.from_coo_list"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.from_coo_list()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.from_torch_sparse_list"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.from_torch_sparse_list()</span></code></a></li>
<li><a class="reference internal" href="#id38"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.shapes</span></code></a></li>
<li><a class="reference internal" href="#id39"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.device</span></code></a></li>
<li><a class="reference internal" href="#id40"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.dtype</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.to"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.to()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.cuda"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.cuda()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.cpu"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.cpu()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.solve"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.solve()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.is_symmetric"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.is_symmetric()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.is_positive_definite"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.is_positive_definite()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.norm"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.norm()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.eigs"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.eigs()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.eigsh"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.eigsh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.svd"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.svd()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.condition_number"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.condition_number()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.SparseTensorList.spy"><code class="docutils literal notranslate"><span class="pre">SparseTensorList.spy()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#dsparsetensor">DSparseTensor</a><ul>
<li><a class="reference internal" href="#torch_sla.DSparseTensor"><code class="docutils literal notranslate"><span class="pre">DSparseTensor</span></code></a><ul>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.from_sparse_tensor"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.from_sparse_tensor()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.from_torch_sparse"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.from_torch_sparse()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.from_global_distributed"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.from_global_distributed()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.from_device_mesh"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.from_device_mesh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.shape"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.shape</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.num_partitions"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.num_partitions</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.device"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.device</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.dtype"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.dtype</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.nnz"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.nnz</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.partition_ids"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.partition_ids</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.is_cuda"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.is_cuda</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.to"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.to()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.cuda"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.cuda()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.cpu"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.cpu()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.halo_exchange_local"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.halo_exchange_local()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.matvec_all"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.matvec_all()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.solve_all"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.solve_all()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.solve_distributed"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.solve_distributed()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.gather_global"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.gather_global()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.scatter_local"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.scatter_local()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.to_sparse_tensor"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.to_sparse_tensor()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.gather"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.gather()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.eigsh"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.eigsh()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.eigs"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.eigs()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.svd"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.svd()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.norm"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.norm()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.condition_number"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.condition_number()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.T"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.T()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.to_dense"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.to_dense()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.is_symmetric"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.is_symmetric()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.is_positive_definite"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.is_positive_definite()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.lu"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.lu()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.spy"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.spy()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.nonlinear_solve"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.nonlinear_solve()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.save"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.save()</span></code></a></li>
<li><a class="reference internal" href="#torch_sla.DSparseTensor.load"><code class="docutils literal notranslate"><span class="pre">DSparseTensor.load()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=b14783f5"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>